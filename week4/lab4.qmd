---
title: "Lab 4"
subtitle: "Permutation and bootstrapping in R"
toc: true
editor: visual
format:
  html:
    other-links:
      - text: Download Source
        href: lab4.qmd
      - text: Eel Grass Restoration Data
        href: data/eelgrass.csv
editor_options: 
  chunk_output_type: console
---

## Learning objectives

In today's lab you will...

1.  Run a **permutation test** to answer a "yes/no?" question
2.  **Bootstrap a confidence interval** to answer a "how much?" question

```{r}
#| label: setup
#| message: false
#| warning: false

library(tidyverse)
theme_set(theme_classic(14))
set.seed(123)

```

## Eel grass restoration

Recall the eel grass restoration example from yesterday's lecture. The data recorded whether attempts to restore eel grass were successful based on the method used (garden staple or popsicle stick) [@fig-eelgrass-data].

```{r}
#| label: read-eelgrass-data

restoration <- read_csv("week4/eelgrass.csv",
                        show_col_types = FALSE)
glimpse(restoration)

```

```{r}
#| label: fig-eelgrass-data
#| fig-cap: "Success of eelgrass restoration plots by restoration method."

ggplot(restoration, aes(treatment, fill = success_fct)) +
  geom_bar() +
  scale_fill_manual(values = c("firebrick", "cornflowerblue")) +
  labs(x = "Restoration method",
       y = "Sites",
       fill = "Outcome") +
  theme(legend.position = "inside",
        legend.position.inside = c(1, 1),
        legend.justification = c(1, 1))

```

## Permutation test

We want to know if the popsicle stick method works better for restoration than garden staples. This is a *"yes/no?"* question, so we'll use a permutation test for our hypothesis. Recall the steps for hypothesis testing:

1.  Identify the TEST STATISTIC
2.  State your NULL and ALTERNATIVE hypotheses
3.  Calculate the OBSERVED test statistic
4.  Estimate the NULL DISTRIBUTION
5.  Calculate P-VALUE
6.  Compare p-value to CRITICAL THRESHOLD

### Identify the test statistic

**Q1: What is the appropriate test statistic for this question?**

-   Difference of Proportions

### State your null and alternative hypotheses

**Q2: What are your null and alternative hypotheses?**

H0: There is *no difference* in outcomes between garden staple and popsicle stick methods on

HA: Popsicle stick will have *more* successful outcomes than garden staple

### Calculate the observed test statistic

**Q3: How would you calculate the test statistic *for the sample*?**

```{r}
# What Max did 

# Finding the proportions per treatment 
# What is proportion of successes for each treatment? 

restoration_sum <- restoration %>% 
  group_by(treatment) %>%  # Grouping by treatment 
  summarise(prop_success = sum(success)/n()) # Finding proportion of success 

# Difference of propertion 
diff_prop <- restoration_sum$prop_success[2] - restoration_sum$prop_success[1] 


```

```{r}
# What we tried in our groups 



gs_prob <- sum(restoration$success == 1)/nrow(restoration$treatment == "Garden staple")

ps_prob <- sum(restoration$success == 0)/nrow(restoration$treatment == "Popsticle stick")

diff <- ps_prob - gs_prob

diff


  
# SIKE... NOT what we want to see 
sum_df <- restoration %>% 
  group_by(treatment, success_fct) %>% 
  summarise(count_s = n()) %>%  # Counting each treatment per outcome 
  mutate(treat_prob = count_s/sum(count_s)) # Finding proportions 

# Count & proportion columns 
treat_sum <- restoration %>% 
  group_by(treatment) %>% 
  summarise(succ_count = sum(success), 
            treat_prob = succ_count/n())


treat_sum <- restoration %>% 
  group_by(treatment) %>% 
  summarise(propo = sum(success)/n())



# Difference between gs and ps successes: 
  # ps - gs (think popsticle is "better" so it goes first)
dif_proportion <- treat_sum$treat_prob[2] - treat_sum$treat_prob[1]

```

### Estimate the null distribution

This is the key part of a permutation test! Remember, our goal is to estimate the distribution of possible outcomes *under the null hypothesis*. To do that, we have to break the association between treatment and outcome.

**Q4: What column should we shuffle to break the association between treatment and outcome?**

-   We should shuffle between the garden staple and Popsicle stick columns

**Q5: Fill in the following code to perform one permutation and calculate the test statistic.**

```{r}
#| label: q5
#| eval: false

# Assuming no difference... ploting the Null 

# Shuffled the dataframes - to remove association between treatments 
# Mixes up the treatments to break assocation of success between treatments 
one_permutation <- restoration %>% 
  mutate(treatment = sample(treatment, # Random Sample from treatments 
                      size = length(treatment),
                      replace = FALSE)) 

# Finding prob of success for treatments with no associationship  
permutation_props <- one_permutation %>% 
  group_by(treatment) %>% 
  summarize(prop_sucess = sum(success)/n())

# Difference of proportion with no associationship 
permutation_diff_props <- permutation_props$prop_sucess[2] - permutation_props$prop_sucess[1]

permutation_diff_props

```

That gives us the value of the test statistic for just one permutation. To get a distribution, we have to repeat the process many times. Let's do it 1,000 times.

**Q6: Fill in the following code to perform 1,000 permutations and estimate the null distribution**

```{r}
#| label: q6
#| eval: false

# Putting all code above in a funtion called permute 
permute <- function(i) {
  # Shuffled the dataframes - to remove association between treatments
  one_permutation <- restoration %>%
    mutate(treatment = sample(treatment, size = length(treatment), replace = FALSE))
  
  # Finding prob of success for treatments with no associationship
  permutation_props <- one_permutation %>%
    group_by(treatment) %>%
    summarize(prop_sucess = sum(success) / n())
  
  # Difference of proportion with no associationship
  permutation_diff_props <- permutation_props$prop_sucess[2] - permutation_props$prop_sucess[1]
  
  permutation_diff_props
  
}

# Creating a distribution of diff of prop from null sample 
null_distribution <- map_dbl(1:1000, permute) # permute = function 
# 1000 = sample size 

```

**Q7: Visualize the null distribution using a histogram and show where the observed test statistic falls**

```{r}
#| label: q7

ggplot() + 
  geom_histogram(aes(null_distribution)) + # Null distribution
  geom_vline(xintercept = diff_prop) # Observed Test Stat in first part 


ggplot(tibble(null_distribution), aes(null_distribution)) + 
  geom_histogram(binwidth = 0.04) + 
  geom_vline(xintercept = diff_prop, 
             color = "red")

```

### Calculate the p-value

The p-value is *the probability of a test statistic [at least]{.underline} as extreme as the observed, given the null hypothesis*. In other words, what proportion of the null distribution exceeds the observed?

**Q8: Calculate the p-value using the null distribution and observed test statistic**

```{r}
#| label: q8
#| eval: false

# Summing all values in null distribution that are larger than the dif of proportion 
p_val <- sum(null_distribution >= diff_prop) / length(null_distribution)
# which diff of proportion to ask 
p_val

```

### Interpret the p-value

When interpreting the p-value, we compare it to a *critical threshold*, usually denoted with $\alpha$. By convention, we usually set $\alpha$ to 0.05.

**Q10:** **Given** $p \gt \alpha$**,** **which of the following statements is a correct interpretation and why?**

-   Our evidence is consistent with the hypothesis that restoration method does not influence restoration outcome

-   We cannot reject the hypothesis that restoration method does not influence restoration outcome

## Bootstrap confidence interval

Now let's answer a "how much?" question. We want to estimate an interval that we think contains the population parameter. For that, we use bootstrapping.

Recall the steps for bootstrapping:

1.  Identify the TEST STATISTIC
2.  Substitute sample for population and draw BOOTSTRAP SAMPLES
3.  Estimate the BOOTSTRAP DISTRIBUTION of the test statistic
4.  Calculate the CONFIDENCE INTERVAL

### Identify the test statistic

**Q11: What is the appropriate test statistic for this question?**

### Draw bootstrap samples

This is the key part of bootstrapping! Remember, our goal is to estimate the variation of our population's parameter due to sampling. To do that, we simulate the process of re-doing our experiment, using the original sample as a substitute for the population. To "re-do" our experiment, we have to keep the association between treatment and outcome.

**Q12: Fill in the following code to draw one bootstrap sample.**

```{r}
#| label: q12
#| eval: false


# WHAT MAX DID 
one_bootstrap <- restoration %>% 
  group_by(treatment) %>% 
  mutate(success = sample(success,
                          size = length(success),
                          replace = TRUE)) %>% 
  ungroup()


bootstrap <- function(i) {
  one_bootstrap <- restoration %>% 
    group_by(treatment) %>% 
    mutate(success = sample(success,
                            size = length(success),
                            replace = TRUE)) %>% 
    ungroup() %>% 
    mutate(trial = i)
}

bootstrap_samples <- map(1:1000, bootstrap) %>% 
  list_rbind()
```

```{r}
#| label: q12
#| eval: false

# WHAT I DID 

# bar graph
ggplot(one_bootstrap, aes(treatment, fill = success_fct)) +
  geom_bar() +
  scale_fill_manual(values = c("firebrick", "cornflowerblue")) +
  labs(x = "Restoration method",
       y = "Sites",
       fill = "Outcome") +
  theme(legend.position = "inside",
        legend.position.inside = c(1, 1),
        legend.justification = c(1, 1))



# Random Sample
one_bootstrap <- restoration %>% 
  group_by(treatment) %>% 
  mutate(success = sample(success,
                      size = length(success),
                      replace = TRUE)) %>% 
  ungroup() 

# Finding Proportion 
bootstrap_prop <- one_permutation %>%
  group_by(treatment) %>% 
  summarise(prop_success = sum(success)/n()) 
 
# Difference of proportion 
bootstrap_diff_prop <- bootstrap_prop$prop_success[2] - bootstrap_prop$prop_success[1]


```

**Q13: Fill in the following code to draw 1,000 bootstrap samples.**

::: callout-tip
`list_rbind()` will take a list of data frames and bind them row-wise into one data frame.
:::

```{r}
# WHAT MAX DID 
bootstrap <- function(i) {
  one_bootstrap <- restoration %>% 
    group_by(treatment) %>% 
    mutate(success = sample(success,
                            size = length(success),
                            replace = TRUE)) %>% 
    ungroup() %>% 
    mutate(trial = i)
}

bootstrap_samples <- map(1:1000, bootstrap) %>% 
  list_rbind()

```

```{r}
#| label: q13
#| eval: false


# WHAT I DID 
# IDK if I am doing this right 

bootstrap_fun <- function(i) {
  # Shuffling Samples to break associationship  
  one_bootstrap <- restoration %>%
    group_by(treatment) %>%
    mutate(success = sample(success, 
                            size = length(success), 
                            replace = TRUE)) %>%
    ungroup()
  
  # Finding Proportion
  bootstrap_prop <- one_permutation %>%
    group_by(treatment) %>%
    summarise(prop_success = sum(success) / n())
  
  # Difference of proportion
  bootstrap_diff_prop <- bootstrap_prop$prop_success[2] - bootstrap_prop$prop_success[1]
  
}

# Drawing null distibutions  
bootstrap_null_dist <- map(1:1000, bootstrap_fun) 
#%>% 
#???

ggplot() + 
  geom_histogram(aes(bootstrap_null_dist)) + 
  geom_vline(xintercept = bootstrap_diff_prop)





# What I had written in class ?? 

bootstrap <- function(i) {
  restoration %>% 
  group_by(treatment) %>% 
  mutate(success = sample(success,
                      size = length(success),
                      replace = TRUE)) %>% 
  ungroup() %>% 
  mutate(trial = i)
}

bootstrap_null_dist <- map(1:1000, bootstrap) 
#%>% 
#???

ggplot() + 
  geom_histogram(aes(bootstrap_null_dist))
```

### Estimate the bootstrap distribution of the test statistic

**Q14: Fill in the following code to calculate the test statistic for each bootstrap sample.**

```{r}
#| label: q14

boot_diff_prop <- bootstrap_samples %>% 
  group_by(trial, treatment) %>% 
  summarize(prop_success = mean(success),
            .groups = "drop_last") %>% 
  summarize(diff_prop = prop_success[2] - prop_success[1])

```

**Q15: Visualize the bootstrapped distribution of the test statistic.**

```{r}
#| label: q15

ggplot(boot_diff_prop, aes(diff_prop)) +
  geom_histogram()

```

### Calculate the confidence interval

A confidence interval (CI) is a range we are confident contains the population parameter. The bootstrapped distribution of the test statistic describes where we expect the population parameter to fall. So a 95% confidence interval, for example, spans the range from the 2.5% quantile of the bootstrap distribution to the 97.5% quantile.

**Q16: Find the bounds of the 95% CI.**

::: callout-tip
The `quantile()` function finds quantiles. It's vectorized over the parameter `probs`, so you can find multiple quantiles at once
:::

```{r}
#| label: q16
#| eval: false

restoration_ci <- quantile(boot_diff_prop$diff_prop, c(0.025, 0.975))
restoration_ci

```

**Q17: Update your visual from Q15 to include the observed test statistic with a solid line and the confidence interval represented with dotted lines.**

```{r}
#| label: q17

ggplot(boot_diff_prop, aes(diff_prop)) +
  geom_histogram() +
  geom_vline(xintercept = diff_props, 
             color = "firebrick",
             linewidth = 1.5) +
  geom_vline(xintercept = restoration_ci, 
             color = "firebrick",
             linetype = "dotted",
             linewidth = 1.5)

```

## Permutation vs bootstrap

The visualization you created for Q7 shows the null distribution of the test statistic. The visualization you created for Q17 shows the bootstrapped distribution of the test statistic.

**Q18: What did you do to make the null distribution center on zero? Specifically, what code?**

*Broke the association between treatment and outcome. Sampled treatment without replacement.*

**Q19: What did you do to make the bootstrap distribution center on the observed test statistic? Specifically, what code?**

*Retained the association between treatment and outcome. Grouped by treatment, then sampled with replacement.*

**Q20: What would happen to your bootstrap distribution if you sampled without replacement?**

*Sampling without replacement is just shuffling. Since we sampled within treatments, the bootstrap samples would always match the observed sample. So there would be no variation in the bootstrap distribution of the test statistic.*
